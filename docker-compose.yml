services:
  app:
    container_name: main_app
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"   # FastAPI
      - "8501:8501"   # Streamlit

    # Bind-mount your local code into the container
    volumes:
      - ./:/app

    # (A) Load environment variables from .env file:
    env_file:
      - .env

    # (B) Additional environment variables (optional):
    environment:
      - PYTHONPATH=/app

#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities: [gpu]

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  ollama:
    container_name: ollama
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ./ollama/data:/root/.ollama
      - ./ollama/modelfiles:/modelfiles
  
#    deploy:
#      resources:
#        reservations:
#          devices:
#            - driver: nvidia
#              count: 1
#              capabilities: [gpu]
